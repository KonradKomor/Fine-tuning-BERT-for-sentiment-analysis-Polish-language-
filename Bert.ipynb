{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOI2siuwwyX/L3QJOpO2dEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonradKomor/Fine-tuning-BERT-for-sentiment-analysis-Polish-language-/blob/master/Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW064qOEOxSh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "fWUWfrJJPUKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"Unnamed: 0\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "2bGBhQyhPW9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].replace(['z_minus_m','z_plus_m'],[0,1])"
      ],
      "metadata": {
        "id": "umhCKoibPXSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6ZjYvIgWPcMA",
        "outputId": "1d9151c1-2b34-4735-809e-bec56b7031ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "0      Polecam wszystkim  zwłaszcza tym  dla których ...    1.0\n",
              "1                            Wszystko stare i okropne .     0.0\n",
              "2              Arogancki właściciel ustawiający gości .     0.0\n",
              "3      Pokój relaksu z Jacuzzi  różnorodne usługi  ma...    1.0\n",
              "4      Hotel na bardzo dobrym poziomie zarówno jeśli ...    1.0\n",
              "...                                                  ...    ...\n",
              "26992  Uważała e skoro dawała m te leki które kazała ...    0.0\n",
              "26993                                   Obsługa  olew .     0.0\n",
              "26994  Zaliczenie Na pierwszym kolokwium zrobil prawd...    0.0\n",
              "26995  Hotel nie dysponuje własnym parkingiem  trzeba...    0.0\n",
              "26996  Polecam wszystkim  niezależnie od wieku  popra...    NaN\n",
              "\n",
              "[26997 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-240a52a2-cf5e-4c6b-83fb-d2977f024afa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Polecam wszystkim  zwłaszcza tym  dla których ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wszystko stare i okropne .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arogancki właściciel ustawiający gości .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pokój relaksu z Jacuzzi  różnorodne usługi  ma...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hotel na bardzo dobrym poziomie zarówno jeśli ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26992</th>\n",
              "      <td>Uważała e skoro dawała m te leki które kazała ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26993</th>\n",
              "      <td>Obsługa  olew .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26994</th>\n",
              "      <td>Zaliczenie Na pierwszym kolokwium zrobil prawd...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26995</th>\n",
              "      <td>Hotel nie dysponuje własnym parkingiem  trzeba...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26996</th>\n",
              "      <td>Polecam wszystkim  niezależnie od wieku  popra...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26997 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-240a52a2-cf5e-4c6b-83fb-d2977f024afa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-240a52a2-cf5e-4c6b-83fb-d2977f024afa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-240a52a2-cf5e-4c6b-83fb-d2977f024afa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmG_UGaIPukO",
        "outputId": "62ea7490-11b4-4391-c579-46d90bb11ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "brgnvniFQHfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2AqD0taQZ21",
        "outputId": "961094b6-5e86-418b-eb2a-728dcf3d0c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "metadata": {
        "id": "aooKO1oYQlYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PMNPyKaVr2Y5",
        "outputId": "f9b3a7e8-9036-41e2-c440-8696e2abdde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "0      Polecam wszystkim  zwłaszcza tym  dla których ...    1.0\n",
              "1                            Wszystko stare i okropne .     0.0\n",
              "2              Arogancki właściciel ustawiający gości .     0.0\n",
              "3      Pokój relaksu z Jacuzzi  różnorodne usługi  ma...    1.0\n",
              "4      Hotel na bardzo dobrym poziomie zarówno jeśli ...    1.0\n",
              "...                                                  ...    ...\n",
              "26991  Aby nie zajmować leżaków przed godziną .  pole...    0.0\n",
              "26992  Uważała e skoro dawała m te leki które kazała ...    0.0\n",
              "26993                                   Obsługa  olew .     0.0\n",
              "26994  Zaliczenie Na pierwszym kolokwium zrobil prawd...    0.0\n",
              "26995  Hotel nie dysponuje własnym parkingiem  trzeba...    0.0\n",
              "\n",
              "[26996 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b74e0078-97f8-4fac-acb6-5d0109b71432\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Polecam wszystkim  zwłaszcza tym  dla których ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wszystko stare i okropne .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arogancki właściciel ustawiający gości .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pokój relaksu z Jacuzzi  różnorodne usługi  ma...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hotel na bardzo dobrym poziomie zarówno jeśli ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26991</th>\n",
              "      <td>Aby nie zajmować leżaków przed godziną .  pole...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26992</th>\n",
              "      <td>Uważała e skoro dawała m te leki które kazała ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26993</th>\n",
              "      <td>Obsługa  olew .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26994</th>\n",
              "      <td>Zaliczenie Na pierwszym kolokwium zrobil prawd...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26995</th>\n",
              "      <td>Hotel nie dysponuje własnym parkingiem  trzeba...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26996 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b74e0078-97f8-4fac-acb6-5d0109b71432')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b74e0078-97f8-4fac-acb6-5d0109b71432 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b74e0078-97f8-4fac-acb6-5d0109b71432');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-oOXOmLQtGP",
        "outputId": "4a9bcc8d-2a8a-4c3d-e783-b8794bd89cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 26996 entries, 0 to 26995\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   text    26996 non-null  object \n",
            " 1   label   26996 non-null  float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 632.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.label)\n",
        "plt.xlabel(\"label\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "FimwdQeJQvCC",
        "outputId": "5bdd55b5-a224-47b3-e3cf-d9c27c0acb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 401,
              "height": 261
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'dkleczek/bert-base-polish-uncased-v1'"
      ],
      "metadata": {
        "id": "lKnaFCqHQ5vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "-tSJurSVRLNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1-Z4lmZRVqm",
        "outputId": "993c0b5f-76d8-4070-dc4c-8c9f602336d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 4)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi_Wtba8RZFs",
        "outputId": "10421464-2468-48b5-c144-1e983f16a2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5DviVBtRqj_",
        "outputId": "e02bf3d5-8b2e-4d43-ecd2-67d79ab39b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Md4u1oRTO1",
        "outputId": "a8061523-7590-4a51-fa1f-16858c4b2dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 2)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_txt='To jest tekst przykładowy'"
      ],
      "metadata": {
        "id": "0ODeuzEIRdoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Zdanie: {sample_txt}')\n",
        "print(f'   Tokeny: {tokens}')\n",
        "print(f'Id tokenów: {token_ids}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDk5R5NbRdqS",
        "outputId": "fc01fdb2-0ac5-477e-927a-78d68957ef19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Zdanie: To jest tekst przykładowy\n",
            "   Tokeny: ['to', 'jest', 'tekst', 'przykład', '##owy']\n",
            "Id tokenów: [1907, 1919, 8960, 4046, 2170]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms6xkfjSRdsW",
        "outputId": "6716f1f5-56e3-4b5a-aa4b-92241b2766d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wPXNRX5COCG",
        "outputId": "cf676d31-8528-46fe-9e4a-9915b6d62b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2,  1907,  1919,  8960, 36121,  2101,     4,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMyUsulcRdwM",
        "outputId": "7038e1a3-709c-4d96-d183-458e17cc7be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,  1907,  1919,  8960, 36121,  2101,     4,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjK5Uf7dRdx-",
        "outputId": "e21f0d0b-b5ca-4029-9752-d7dd24fcbfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_ids_to_tokens(encoding['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMpOVsiJR-v3",
        "outputId": "e8f17eb3-1805-4aae-ed50-29ea52453c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'to', 'jest', 'tekst', 'testo', '##wy', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df.text:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "metadata": {
        "id": "31hxpb-6R-xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Liczba tokenów');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "mVtPcOw_R-zz",
        "outputId": "9f657c16-d189-41e8-80a2-81e6240206a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxMAAAILCAYAAACTqMESAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxcZ33n+8/T1bu6W2ptLduSbMuWLTngeAu2MQ4QB8JAJpgkzCvDDcmwTEJYE5J7J5ckYLiXbHdCMAGSV4YBgicOyc0MkEAuGIxZDTbYgMHWhm1JlrW09t7Xeu4fVV19qt1Sb9V96lR93q+XXrWdOudpGpLz7d/ze54QY0SSJEmSFqoh7QFIkiRJyibDhCRJkqRFMUxIkiRJWhTDhCRJkqRFMUxIkiRJWhTDhCRJkqRFMUxIkiRJWhTDhCRJkqRFMUxIkiRJWhTDhCRJkqRFMUxIkiRJWhTDhCRJkqRFaUx7AJoWQngS6AL2pzwUSZIk1bZLgL4Y46VLOYlhorp0tbW1rd25c+fatAciSZKk2rVr1y6Gh4eXfB7DRHXZv3PnzrUPPfRQ2uOQJElSDbv++ut5+OGH9y/1PPZMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRTFMSJIkSVoUw4QkSZKkRWlMewBK390PHJzXca+6cesyj0SSJElZYmVCkiRJ0qIYJiRJkiQtimFCkiRJ0qIYJiRJkiQtimFCkiRJ0qIYJiRJkiQtimFCkiRJ0qIYJiRJkiQtimFCkiRJ0qIYJgTA+GSeyXxMexiSJEnKkMa0B6D0HT4zzH/7+hMA3Lp9Pc+7fAPNjeZMSZIknZ93jOJr+44zOpFndCLPl3b18hdf3MOjh8+mPSxJkiRVOcNEnRsZn2T3kf6y9/pHJviHBw9yrG8kpVFJkiQpCwwTde4re3oZm8wD0NnSSGdrYeZbPsIPnjqT5tAkSZJU5QwTde6zjxwpPb/hkrW8/CcvLL1+5OmzxGhTtiRJkmZnmKhjw2OT3Lurt/T62ZtXs72nk5Zi8/WpwTEOn3GqkyRJkmZnmKhj9+3pZXh8EoANnS30dLbQlGtg5wVdpWMeedqpTpIkSZqdYaKOfS4xxenZF60mhADA1RetLr3/Q6c6SZIk6RwME3VqaGyCe3cfK71+diJAXN7TQWtT4b8aZ4bGOXR6eMXHJ0mSpOpnmKhTDz55ipHxwipOGztb6OlqLX3W2NDAVRdMh4tHDjnVSZIkSc9kmKhTB04OlZ5vXdv+jM+v3jwdJn50uM+pTpIkSXoGw0SdeurUdJhYu6r5GZ9ftqGjtKrT2eFxTg+Nr9jYJEmSlA2GiTr11OnpMNHd/swwkWsIbElULJLhQ5IkSQLDRN166tR0U3X3LJUJgC3d02Hi4GnDhCRJksoZJupQjLGs0tDd3jTrcVutTEiSJOk8DBN16OzwOP2jEwC0NeXoaGmc9bgt3W2l50fOjDBS3OBOkiRJAsNEXUpOcdrc3VbarG6m9pZG1ncUpkBNxsijh8+uyPgkSZKUDYaJOpRsvp5tWdikZN/E9w6634QkSZKmGSbqULL/YcscYWLrOsOEJEmSZmeYqEPJysTmRF/EbMorE6eXbUySJEnKHsNEHUr2TMxVmejpaqUpV+ipOHx2hKNnR5Z1bJIkScoOw0QdKpvm1H3+MJFrCGy2OiFJkqRZZDJMhBA2hxA+GkI4HEIYDSHsDyG8P4TQvcDzrC1+b3/xPIeL5908z+//agghFv+9fnE/zcrK5yOHTicrE+ef5gTlTdrfe8q+CUmSJBXMvsFAFQshXAbcD2wEPgPsBp4DvA14SQjhlhjjyXmcZ13xPFcAXwY+CewAXgO8LIRwc4zxifN8fwvwQWAA6FjSD7WCevtHGZvMA4XN6jpbZ9+wLilZvfi+YUKSJElFWaxMfJhCkHhrjPH2GOPvxxh/BvhL4ErgvfM8zx9TCBLvizHeVjzP7RRCycbidWYVChszfAw4CfzN4n+UlZdsvp6rX2LKhWtaS893HekjxljxcUmSJCl7MhUmilWJFwP7gQ/N+PhdwCDw6hDCqjnO0wG8unj8HTM+/iBwAPi5EMK2c5zircDPUKhiDM7/J0jfQvolpqxua6K1qfBflf6RCQ7bhC1JkiQyFiaAFxYf74kx5pMfxBj7gW8C7cBNc5znJqAN+Gbxe8nz5IEvzLheSQhhJ/CnwJ0xxq8t+CdIWdnu1/PolwAIIbCpa/rY3Uf6Kj4uSZIkZU/WwsSVxce95/h8X/HxiuU4TwihEbgLOAi8Y45rnFMI4aHZ/lHo2VhWBxdRmQDYtHp6qtPuo/3nOVKSJEn1ImsN2KuLj2fP8fnU+2uW6TzvBK4FnhdjHCaDkj0TW+fZMwFwQVd534QkSZKUtTCRmhDCjRSqEX8RY/zWUs4VY7z+HNd4CLhuKeeey6FTC2/ABisTkiRJeqasTXOaqhisPsfnU+/PtX7pgs5TnN70CQrTov5o7mFWp/HJPEf7Cs3TIZSv0jSXnq5WQmEjbJ44PsDI+ORyDFGSJEkZkrUwsaf4eK6eiO3Fx3P1Qiz2PB3FY3cCI4mN6iKFVaQA/lvxvffPce3UnBocI19c1XXdqmZaGnPz/m5zYwOXrCsskpWP8OPegeUYoiRJkjIka9Oc7is+vjiE0JBc0SmE0AncAgwB357jPN8GhoFbQgidyRWdQggNFJafTV5vFPjv5zjXdRT6KL5BIaQsaQrUcjo9NFZ63t3evODv79jUyZMnCivh7jrSx7MuOldhR5IkSfUgU5WJGOPjwD3AJcCbZnz8bmAVcFeMsbT3QwhhRwihbJWkGOMAhVWZVvHMfSbeXDz/F6Z2wI4xDscYXz/bP+Bfit/7u+J7/1iBH3VZnB4cLz1fXJjoKj23b0KSJElZq0wAvBG4H/hACOE2YBdwI4U9IfYCfzDj+F3FxzDj/XcALwDeHkK4BniQwjSmlwO9PDOsZF6yMrGmvWnB399xQWfp+e6jrugkSZJU7zJVmYBSdeIG4OMUQsTvApcBdwI3xRhPzvM8J4GbgQ8AlxfPcyPwMeD64nVqylKnOe1MVCZ2HeknxliRcUmSJCmbsliZIMb4FPCaeR47syKR/OwU8Lbiv8WO5Q6eOVWqKp0ZSkxzWrXwMLG5u41VzTkGxyY5NTjG8f5RNnbNf0UoSZIk1ZbMVSa0eKcGk5WJhU9zamgIXLlpeqrTLvsmJEmS6pphoo4sdZoTwI4LklOd7JuQJEmqZ4aJOpKc5rSYBmwoLA87Ze8xKxOSJEn1zDBRR5KVibWL6JkA2L5xOkzsO+bGdZIkSfXMMFFHTg8ml4ZdXJi4oqej9Hxfbz/5vCs6SZIk1SvDRB05nVzNaZHTnNZ1tLC+oxBERsbzPHV6qCJjkyRJUvZkcmlYLdxkPtI3Mh0mVrctPEzc/cBBALpamzgxUKhyfOTrT7Iz0ZQ95VU3bl3kSCVJkpQVVibqxNnhcab2mFvd1kRjbvG/+uTeEsf6RpY6NEmSJGWUlYkaNVVFmNLbP33T39gQnvH5QvR0tSTOO7ro80iSJCnbrEzUieGxydLz9ubcks7V02llQpIkSYaJujFUFiaWVpDqSUxzOt4/Sj66opMkSVI9MkzUiaGxidLzpVYm2ppzdLYWAslEPnJqYGyOb0iSJKkWGSbqxOBo5aY5wYypTv1OdZIkSapHhok6UTbNqWXpfffJJmz7JiRJkuqTYaJOVHKaE8xcHtYVnSRJkuqRYaJOVLIBG6CnM7k8rJUJSZKkemSYqBPLWZk40T/GZN4VnSRJkuqNYaJODFVwnwmA1qYcq9uaAJiMkZMDTnWSJEmqN4aJOlHpaU4wownbnbAlSZLqjmGiDsQYKz7NCWCjO2FLkiTVNcNEHRidyDPV0tCca6ApV5lfe7Iy0WuYkCRJqjuGiTpQ6X6JKT3J5WGd5iRJklR3DBN1YDmmOAFsSCwPe3JglInJfMXOLUmSpOpnmKgDg6OVb74GaGnM0d1eWNEpH+HEwFjFzi1JkqTqZ5ioA2WViZbKVSZgRhO2m9dJkiTVFcNEHViungko75uwCVuSJKm+GCbqwHLsMTGlbK+JPpuwJUmS6olhog4sVwM2wMYu95qQJEmqV4aJOrCclYkNHS2E4vNTg2OMu6KTJElS3TBM1IHlrEw0NzawdlUzABE47n4TkiRJdcMwUQeWswEbnOokSZJUrwwTdWB0YnrqUWtT5cNET2Lzul4rE5IkSXXDMFEHRsanKxMtjZX/lVuZkCRJqk+GiTowlqhMtDQuQ2Wiy8qEJElSPTJM1LiJyTwT+QhAQ4CmXJjjGwu3oaOFhuJpTw+OlYUXSZIk1S7DRI0bnVGVCKHyYaIx18C6VYXqRAR6+53qJEmSVA8MEzWuPEws36+7fCdsw4QkSVI9MEzUuNGJRPN10zKGidXJJmz7JiRJkuqBYaLGjY4vb/P1lJ5OV3SSJEmqN4aJGldWmVjGaU6bEsvDHjVMSJIk1QXDRI0bSfZMLMOGdVPWdjTTWFzSqX9kgtODY8t2LUmSJFUHw0SNGxtfmQbshhDYmGjC3nusf9muJUmSpOpgmKhxI4lpTq3LGCagvG/CMCFJklT7DBM1bnSFpjkB9CT6JnYfNUxIkiTVOsNEjRsdX5kGbCgPE1YmJEmSap9hosbN3AF7OW1K7DWx52g/McZlvZ4kSZLSZZioceXTnJb3193V2khr8Rp9IxNuXidJklTjDBM1bqX2mQAIIZQ1Ye8+2res15MkSVK6DBM1bmSFdsCe0rPavglJkqR6YZiocWOJaU6tyzzNCcqbsPccHVj260mSJCk9hokaN1I2zWkFKhOJjev2HHOakyRJUi0zTNS40RXaAXvKpkTPxL5jA0zmXdFJkiSpVhkmaliMcUUbsAHaWxrpbG0ECitJHTw1tOzXlCRJUjoMEzVsIh+ZKgzkGgKNuZX5dZf3TdiELUmSVKsMEzWsfMO6lftV93Qm+iYME5IkSTXLMFHDRsdXdorTlGRlwuVhJUmSapdhooaNlC0Lu/wrOU3ZlNhrYo9hQpIkqWYZJmrYSjdfT9mYWNHpyRODZeOQJElS7TBM1LDRFd79ekpzYwNb17YDMJmPPN47uGLXliRJ0soxTNSwsgbsFdj9OunKTZ2l5/ZNSJIk1SbDRA1La5oTwJU902HCvglJkqTaZJioYWlNcwK4IlGZcHlYSZKk2mSYqGFllYmVnubUY5iQJEmqdYaJGjYykV5l4tL1q2jKBQCePjNM/8j4il5fkiRJy88wUcOS05xaV7hnormxgW3rO0qv9/UOrOj1JUmStPwMEzWsfJrTylYmwL4JSZKkWmeYqGFlS8OucGUC4Mqe6cqEYUKSJKn2NKY9AC2f0fH0loa9+4GDHD07Unr9jX0nuPuBg8847lU3bl3JYUmSJKmCrEzUsPJN61Z+mtPGrtbS82P9I+c5UpIkSVlkmKhhaU9zWruqmcaGwopO/SMTDI9NzvENSZIkZYlhooYlG7BbV3hpWICGENjQ2VJ63Wt1QpIkqaYYJmpUjLFsadjmFCoTQHmY6BtNZQySJElaHoaJGjU2mScWnzflArnidKOV1mPfhCRJUs0yTNSo0RR3v07aWDbNycqEJElSLTFM1KjkFKc0mq+n9HROVyZ6+6xMSJIk1RLDRI0q3/06vV9z96rm0hSrPld0kiRJqimGiRpVLdOccg2BDR2u6CRJklSLDBM1Ks3dr2fa2GXfhCRJUi0yTNSoZGWiNYXdr5M22jchSZJUkzIZJkIIm0MIHw0hHA4hjIYQ9ocQ3h9C6F7gedYWv7e/eJ7DxfNuPsfxfxZCuDeE8FQIYTiEcCqE8L0QwrtCCOsq89NVxkjKu18nuaKTJElSbcpcmAghXAY8BLwGeBD4S+AJ4G3At+Z7U1887lvF7z1ePM+DxfM+FELYNsvXfgdYBXwRuBP4e2ACuAN4JISwZdE/WIVV0zSnsr0mrExIkiTVjMa0B7AIHwY2Am+NMf7V1JshhPdRuNl/L/CGeZznj4ErgPfFGH83cZ63UggKHwZeMuM7XTHGZ9wNhxDeC7wD+D+BNy7op1kmZQ3YKU9zWltc0WkyH+kbmWBkfDL1qVeSJElaukxVJopViRcD+4EPzfj4XcAg8OoQwqo5ztMBvLp4/B0zPv4gcAD4uZnVidmCRNE/FR+3n/8nWDmjVTTN6RkrOlmdkCRJqgmZChPAC4uP98QY88kPYoz9wDeBduCmOc5zE9AGfLP4veR58sAXZlxvLv+++PjIPI9fdmOJMNGcS//XvMG+CUmSpJqTtWlOVxYf957j830UKhdXAPcu8TwUz/MMIYTfAzqA1cANwPMoBIk/Pc81k99/6Bwf7ZjP9+djbDIRJlKuTAD0dLXww6cLz+2bkCRJqg1ZCxOri49nz/H51Ptrlvk8vwf0JF5/HvhPMcbjc1x3xYxXWWWibHlYKxOSJEk1IWthoirEGDcBhBB6gOdSqEh8L4Tw8zHGh+fx/etne79YsbiuEmNM9kw0VUFlwo3rJEmSak/6d5kLM1UxWH2Oz6feP7MS54kxHosxforC1Kp1wCfmuO6KGZ+srsrEulUt5EIA4OzwOCOJpWslSZKUTenfZS7MnuLjrL0MTK+mdK5eiEqfB4AY4wHgMeAnQgjr5/Od5VbWgF0FlYlcQ2B9Z3PptdUJSZKk7Ev/LnNh7is+vjiEUDb2EEIncAswBHx7jvN8GxgGbil+L3meBgqVhuT15uPC4mNV/Mm92hqwYUbfhE3YkiRJmVcdd5nzFGN8HLgHuAR404yP301hd+q7YoyDU2+GEHaEEMpWSYoxDgB3FY+/Y8Z53lw8/xdijE8kznNFCOEZ06JCCA3FTes2AvfHGE8v6oersGpbGhbsm5AkSao1WWzAfiNwP/CBEMJtwC7gRgp7QuwF/mDG8buKj2HG++8AXgC8PYRwDfAgsBN4OdDLM8PKS4E/CSF8A3gSOElhRafnA9uAo8B/XuLPVjFVX5notzIhSZKUdZkLEzHGx0MINwDvAV5C4Sb/CHAn8O75VgZijCdDCDdT2Dn7duBWCgHhY8A7Y4yHZnzlS8DlFPaUuJbCsrGDFALMXcAHYoynlvjjVcTEZJ7JfAQKCaqxYWaOSkdPYuO6Y31WJiRJkrIuc2ECIMb4FPCaeR57zjvp4s3/24r/5jrPjyhMgap6Q4mVkpobGwihOsLEuo7Cik6TMbqikyRJUg2ojvkvqqjhsUSYqJJ+CSis6LSuY3pFp+P2TUiSJGVa9dxpqmIGRydKz6thw7qkjV32TUiSJNWK6rrTVEUMVWllAuybkCRJqiXVdaepihie0TNRTaxMSJIk1Y7qutNURZRVJqotTCQqE71WJiRJkjKtuu40VRHDY9M9E9U2zWldRzNTK9WeGR5nINHfIUmSpGyprjtNVcTgaPVWJhobGljfMV2d+HHvQIqjkSRJ0lJU152mKqJsn4kqq0xA+VSnfcf6UxyJJEmSlqL67jS1ZGXTnKqsMgHlTdj7rExIkiRlVvXdaWrJkg3YTVYmJEmStEyq705TS1bNqzkB9CQqE3uPWZmQJEnKquq709SSDZWt5hRSHMnskis6PX1muGzHbkmSJGWHYaIGlVcmcimOZHaNDQ2sc0UnSZKkzDNM1KDhKp/mBDP6JgwTkiRJmVSdd5pakrLKRBVOc4LyvgmbsCVJkrLJMFGDkj0TTVYmJEmStEyq805TS5KsTLTkqq9nAsr3mthrZUKSJCmTDBM1KNkz0dRYndOc1q+aXtHp0OnhsmqKJEmSssEwUYPKeyaq81fcmGtg3SpXdJIkScqy6rzT1JIMJveZqNKeCYCNXcmdsA0TkiRJWVO9d5patOEMVCYANnYm+iZ67ZuQJEnKmoreaYYQfjGEUJ0dv3VibCLPRD4C0BAg11CdPRNQXpn4sZUJSZKkzKn0n63/GTgQQnhPCGFrhc+teZi5YV0I1RsmehKViT2u6CRJkpQ5lQ4THwLagT8EHg8h/GsI4edDNd/R1pih8US/RBVPcQJY39lMY7Fycuj0MAOjrugkSZKUJRW924wxvgW4EHgt8F3gZcBnKFQr3hlCuLCS19MzDY4mloWt8jDR2NDAtg2rSq/db0KSJClbKn63GWMciTF+PMZ4M3A18GGgA7gD2B9C+FQI4SWVvq4KktOcWqp4JacpV/R0lp7vPWqYkCRJypJlvduMMf4oUa14DXAM+AXgcyGEJ0MIvxdCWHXek2hBkpu/NWUgTOzYNB0mdhsmJEmSMmXZ7zaLYeHXgLcAFwEB+AGwDvhzYHcI4ZrlHke9GBrPxrKwU8oqE05zkiRJypRlu9sMIVwbQvgb4DDwN8AO4CPAdTHG6yhUK34fWA98YLnGUW+GRstXc6p2OzZ1lZ7vsTIhSZKUKY2VPFkIoR34j8BvAtdTqELsohAm/i7G2Dd1bIxxAPjzEMIW4HWVHEc9S05zykJlYnN3G+3NOYbGJjk5OMbx/lE2dLbM/UVJkiSlrqJhgkIVohOYBP4n8OEY41fm+M7TQOscx2iehsezVZloaAhs7+nkB0+dAQpTnQwTkiRJ2VDpu81+Cqs2bY0x/od5BAkorPZ0aYXHUbeGxrLVMwGwo8cmbEmSpCyqdGXi4hhjfiFfKE596pvzQM1LMkxkYTUngCs2uTysJElSFlX6bvNLIYRfO98BIYRfDSF8ucLXVdHQaLZ6JmDG8rCu6CRJkpQZlb7bfAFwyRzHXAw8v8LXVdFQxnomoHx52H3H+snnY4qjkSRJ0nylcbfZBkzMeZQWJbkDdlbCxIbOFtatagYK07QOnR5OeUSSJEmaj0r3TADM+mflEEIAtgIvBZ5ahuuK7C0Ne/cDBwFY3d7EycExAP72a09w1YVdZce96satKz42SZIknd+S7zZDCPkQwmQIYepP4ndMvU7+o1CNeAK4BvjkUq+r2Q1lsDIB0NM1vTrwsf6RFEciSZKk+apEZeJrTFcjfho4COyf5bhJ4CRwL4WdsLUMylZzykBlYsqmRJg4etYwIUmSlAVLDhMxxhdMPQ8h5IGPxRjfs9TzanGSYaIlq5WJPsOEJElSFlS6Z+JS4EyFz6kFGM5Yz8SUnsSu1ycGRpmYzNOYofFLkiTVo4rercUYD8QYz1bynFqYLG5aB9DSlKO7vQmAfITjA6Mpj0iSJElzWVJlIoTwTgr9Eh+KMZ4qvp6PGGP8v5Zybc2urAE7Y3/Z7+lq5fTQOADH+ka5YHVbyiOSJEnS+Sx1mtMdFMLEPwKniq/nIwKGiQqLMZYvDZuhygQUmrB3Hy3sgG3fhCRJUvVbaph4YfHx4IzXSsHoRJ6pzaNzDYFcQ0h3QAvU44pOkiRJmbKkMBFj/Or5XmtlDWd4ihNAz2r3mpAkScqS7N1x6pyGxrO5Yd2U9R3NTBVTzgyNM5L4eSRJklR9KnrHGUK4JITw0hDCqsR7jSGEd4cQfhBCuD+E8IpKXlPThkan+yWytGHdlMaGBjYklojttW9CkiSpqlX6jvNdwF1Acl3PPwT+CHg2cBPwTyGEmyp8XZHdDeuSyvom+lweVpIkqZpV+o7zZuDeGOMEQAihAXgjsBvYCjwHGAR+p8LXFTP2mMhgZQIKKzpNcUUnSZKk6lbpO84e4EDi9TXAegr7UByKMX4X+AzwUxW+roDh8eSysNlayWlKeWXCMCFJklTNKh0mmijsITHlluLrLyfeOwRcUOHrChgczfZqTlAeJo71jRBjPM/RkiRJSlOl7zgPAVcnXr8UOBFj3JV4byPQV+HrChjO+GpOAGvam0pjHxqbZCDRVC5JkqTqUuk7zs8CLwoh/NcQwv8NvAj4lxnHXEH5VChVyHAN9Ew0hEBPYkUnpzpJkiRVr0rfcf458CTwduAdwBEKKzwBEELYSKFJ+2sVvq4ob8DOamUCZk51ckUnSZKkarWkHbBnijH2hhCeDdxWfOurMcb+xCHrgf8d+EIlr6uC5DSnrFYmADYld8I+a2VCkiSpWlU0TADEGIcpTHea7bPHgMcqfU0VDI8lVnPKcJhwRSdJkqRsyO4dp56hFqc59faPkHdFJ0mSpKpU8cpECGEt8FoKG9R1A7lZDosxxttmeV9LUAsN2AAdLY10tDQyMDrB+GTk9OBY2kOSJEnSLCoaJkIIO4CvABuA8+2a5p+al0EtLA07paerhYHjhWlb7oQtSZJUnSp9x/lfKewj8WfANqApxtgwy7/ZqhVaorJpTrls7oA9ZZN9E5IkSVWv0tOcbgU+F2N8R4XPq3kom+aU+cpEMky4PKwkSVI1qvQdZ8DVmlJTNs0pwz0TMHOvCSsTkiRJ1ajSd5wPAVdW+Jyap6HE0rBZbsAG2Ng1vQv2yYFRRicmz3O0JEmS0lDpO873AC8NIbygwufVPAzXyNKwAC2NOdauagYgH+Hx3sGURyRJkqSZKt0zsQX4DHBPCOEfKFQqzsx2YIzxExW+dt0bqqFpTlCY6nSquCzsnmN9XHVhV8ojkiRJUlKlw8THKSz7GoBXF//NXAY2FN8zTFRYrewzMaWnq4VdRwrPdx/tT3cwkiRJeoZKh4nXVPh8mqfJfGR0Ig9ACNCU8aVhoXx52L2GCUmSpKpT0TARY/y7Sp5P85dcyamtKUcI2Q8TyRWd9hgmJEmSqk7258IIKJ/i1NZUG3sCru9oIVcMRYfPjnB2eDzlEUmSJClpWcJECGFDCOENIYQ7QwgfmfH+c0IIbctx3XpWFiaaayNM5BoCGzqnl4j9ca/VCUmSpGpS8TARQngdsB/4EPAWyvsoeoBvAa+q9HXr3dD49B4T7TUSJqB8v4k9RwdSHIkkSZJmqmiYCCG8CPhbYC/wCuCvk5/HGH8EPArcXsnrCobKKhOV7qtPT1kT9jErE5IkSdWk0ned/wU4Ajw/xtgXQrh2lmMeAW6u8HXr3khZz0TttMLYhC1JklS9Kn3XeQPw2Rhj33mOOQRsqvB1616yMtFeQwi2M7oAACAASURBVJWJZJjYZ8+EJElSVal0mGgGBuc4Zg0wOccxWqDk7te10oANsKa9qbRnxomBMU4MjKY8IkmSJE2pdJjYD1w/xzE3AnsqfN26Nzw23YBdK0vDAjSEwMZO+yYkSZKqUaXDxGeAW0MIr5ztwxDCa4Crgf9Z4evWveGyaU61EyagfKqTO2FLkiRVj0pPrv9z4FeAfwgh/DKwGiCE8GbgVuAXgX3AX1X4unWvVqc5AfQklofd2+vysJIkSdWiopWJGONp4PnAN4BXAi8GAvCB4uv7gdtijHP1VZxXCGFzCOGjIYTDIYTREML+EML7QwjdCzzP2uL39hfPc7h43s2zHLsuhPD6EMKnQgg/DiEMhxDOhhC+EUJ4XQgh1SWUyioTTbXTgA1WJiRJkqpVxe86Y4wHgReEEK6msATsOuAs8O0Y40NLPX8I4TIKoWQjhWlVu4HnAG8DXhJCuCXGeHIe51lXPM8VwJeBTwI7KGyy97IQws0xxicSX3klhX0zjgD3AQcpbML3i8BHgH8XQnhljDEu9WdcjPIdsGtnaViYsTzssX5ijIQQUhyRJEmSYBnCxJQY4yMU9pSotA9TCBJvjTGWpkuFEN4H/A7wXuAN8zjPH1MIEu+LMf5u4jxvBe4sXuclieP3Ar8AfC7GmE8c/w7gQeCXKASLVPpByqc51VZloqu1kc7WRvpHJugfmeBo3wgXrG5Le1iSJEl1b1n+hB1CuDiEcEMI4foQwtYKnvcyClOn9gMfmvHxuygsS/vqEMKqOc7TAby6ePwdMz7+IHAA+LkQwrapN2OMX44x/msySBTfPwr8TfHlCxbw41RU+TSn2uqZCCFwZU9n6fXeY/ZNSJIkVYOKhYkQwvoQwvtCCEeAJ4AHKPzF/sliL8L/E0JYu8TLvLD4eM8sN/X9wDeBduCmOc5zE9AGfLP4veR58sAXZlxvLuPFx4nzHrWMhpJLw9ZYAzbA9mSYsG9CkiSpKlRkPkwIYTvwRWALhYbrCeBk8flaCjtevx34pRDCz87oRViIK4uPe8/x+T4KlYsrgHuXeB6K5zmvEEIj8GvFl5+f6/jid87VO7JjPt+fzfD4dLZqa85xZmj8PEdnz5U9HaXne9xrQpIkqSosuTJRXMXo74GtwFeBnwU6YowXxBg3AZ0UbvC/BlwC/I8lXG518fHsOT6fen/NCp0H4E+BZwH/FmP8wlwHL5fkpnW1Ns0J4IpN05WJPVYmJEmSqkIlKhMvBm4A/gn4jzNXM4oxjgJfCiHcC/wjherEi2KMX6zAtVNVbNb+XQorSr16vt+LMc66S3ixYnHdYsYyVLZpXW01YANlPRP7evuZzEdyDa7oJEmSlKZK9Ez8EjAKvOV8y6IWP3szhf6CX17ktaYqBqvP8fnU+2eW+zzFjfjuBB4DXhhjPDXHNZfV8HjtLg0LsK6jhQ2dhc3rRsbzHDi5pK1KJEmSVAGVuOu8jkIj8/G5Dowx9lLY0G5Rf30H9hQfz9XLsL34eK5eiIqcJ4Tw2xR28f4RhSBxdI7rLbvyfSZqrzIBsCMx1Wm3U50kSZJSV4kwsQV4dAHHPwpcvMhr3Vd8fPHMHadDCJ3ALcAQ8O05zvNtYBi4pfi95HkaKEzdSl4v+fl/Af4S+D6FING70B9iOQzV8NKwU3Ze0FV6bpiQJElKXyXCRBdzTytKOkOhKXvBYoyPA/dQaOR+04yP3w2sAu6KMZbmwIQQdoQQylZJijEOAHcVj79jxnneXDz/F2auOhVC+CMKDdcPAbfFGE8s5udYDuWVidoME2WViSN9KY5EkiRJUJkG7GZgcs6jpuWL31msNwL3Ax8IIdwG7AJupLAnxF7gD2Ycv6v4OLNb9x0UNpl7ewjhGgp7YuwEXg70MiOshBB+HXgPhZ/168BbQ3hGA/D+GOPHF/lzLdrEZJ6xycLSsCFAS2Pt9UwA7NhkZUKSJKmaVGpy/Tkbrystxvh4COEGCjf2LwFeChyh0Az97hjj6Xme52QI4WYKO2ffDtxKYW+MjwHvjDEemvGVS4uPOeC3z3HarwIfn/9PUxnJ5uv2phyzhJyacNnGVTQ2BCbykYOnhhgYnaCjpTb7QyRJkrKgUndid4QQ7qjQueYUY3wKeM08jz3nnXVxBaa3Ff/NdZ47eOaUqKpQD83XAC2NOS7b0FHatG7P0X6uv7g75VFJkiTVr0rNhwkL/KcKGhqr7WVhk64sW9HJvglJkqQ0LfnOM8bYsIh/tdkhnJLyaU61W5kA2HFBsgnbvglJkqQ01fafsevEUB2s5DRlZ1kTtpUJSZKkNBkmakCyZ6K9xsPEzMrEeTZdlyRJ0jIzTNSA5DSnthrdsG7Kpq5WVrc1AdA/OsHTZ4ZTHpEkSVL9MkzUgKGxidLzWp/mFEKYsXmdfROSJElpMUzUgHqa5gSw8wL7JiRJkqqBYaIGlDVg1/g0J6CsMrHLyoQkSVJqDBM1oKxnooY3rZty1YXTlYlHD59NcSSSJEn1rfbvPOtAPUxzuvuBg6Xn45N5GgLkI+w/OcRHv/EkrYmKzKtu3JrGECVJkuqOlYkaMFQHYSKpKddAT1dr6fXhs67oJEmSlAbDRA1ITnNqrYOeCYALV7eVnh8+M5LiSCRJkuqXYaIGDCeWhq2HygTAhWumKxNH3GtCkiQpFYaJGlBv05wALlwzXZlw4zpJkqR0GCZqQD1Oc9q0upVQfH68f5SxiXyq45EkSapHhokaUL6aU30s0NXSmGN9RwsAETjaZ9+EJEnSSjNM1IB6nOYE5X0Th53qJEmStOIMEzWgfNO6egoTyRWdDBOSJEkrzTBRA5LTnNrqpGcCZoQJ95qQJElacYaJGjBUh0vDQvleE8fOjjKRtwlbkiRpJRkmakC9TnNqa87R3d4EwGSM9PaNpjwiSZKk+mKYyLjxyTzjkxGAhgDNufr6lbrfhCRJUnrq686zBiWrEu3NjYQQznN07dmcCBOHTg+lOBJJkqT6Y5jIuLLm6zqa4jRl89r20vOnTlmZkCRJWkmGiYwbHJ1uvl5Vh2HiojVtpZ2wj/WNMDoxed7jJUmSVDmGiYwbqsPdr5Nam3Js6JzeCfvwGXfCliRJWimGiYwrq0y01F9lAmBL2VQn+yYkSZJWimEi4+q9MgGwpTsRJmzCliRJWjGGiYwbHLMysbk7uaKTTdiSJEkrxTCRcUOjViZ6ulppyhXasM8Oj3Osz74JSZKklWCYyLiyykQdruYEkGsIXJTYb+L7T51JcTSSJEn1wzCRcWU9Ey31WZmA8r4Jw4QkSdLKMExkXL3vMzEluXnd9w8aJiRJklaCYSLjXM2pYEuiCfuRQ2eYzMcURyNJklQfDBMZ5z4TBavbmugsTvMaHJvk8eMDKY9IkiSp9hkmMs7KREEIwalOkiRJK8wwkXHuMzEtOdXpezZhS5IkLTvDRMa5z8S0za7oJEmStKIMExlXvs9EvYeJNkLx+Z6jfQwl/rORJElS5RkmMq58n4n6nubU2pRjQ2cLAPkIP3q6L+URSZIk1TbDRMaV7zNR35UJmLl53ekURyJJklT7DBMZZ2Wi3Oa1003Y9k1IkiQtL8NEhsUYy3om2psME2WVCZeHlSRJWlaGiQwbGc8Tixs9tzQ20Jjz19nT1UprU+E/h8NnR+jtG0l5RJIkSbXLu88MK99jwn4JgFxD4NkXrS69dqqTJEnS8jFMZFj5HhNOcZpyzZY1peeGCUmSpOVjmMgw95iY3TVbukvPDROSJEnLxzCRYclN2VzJadpPbpme5vTIobNM5mOKo5EkSapdhokMG0xMc7IyMe2iNW1sLG5eNzA6wd5j/SmPSJIkqTYZJjKsrDJhz0RJCIHrL56e6vTQATevkyRJWg6GiQwrq0y4mlOZZJh42DAhSZK0LAwTGWZl4tyuS4aJg4YJSZKk5WCYyLDBMSsT5/ITF3bR3Fj4r/f+k0OcGBhNeUSSJEm1xzvQDBsatTIxm7sfOAjABV2tHDg1BMD7v7iPqy7sKjvuVTduXfGxSZIk1RIrExlWVplwNadn2Lq2vfT84KnBFEciSZJUmwwTGeY+E+e3dd10mJiqUEiSJKlyDBMZ5j4T55esTDx9epiJfD7F0UiSJNUew0SGuZrT+XW2NrF2VTMAE/nIkTMjKY9IkiSpthgmMsx9JuaWrE441UmSJKmyDBMZZmVibuVN2IYJSZKkSjJMZJj7TMzt4kQT9sGTg8QYUxyNJElSbTFMZJj7TMytp6u1tHld38gEZ4fHUx6RJElS7TBMZJj7TMytIQS2dLeVXts3IUmSVDmGiQxzn4n52bp2Ven5wZOGCUmSpEoxTGTU2ESe8cnC/P/GhkBzzl/luZT1TViZkCRJqhjvQDNq5kpOIYQUR1PdtnRPh4kjZ4cZm3DzOkmSpEowTGSUKznNX1tzjo2dLQDkIxw6bXVCkiSpEgwTGeVKTgvjVCdJkqTKM0xklJWJhSlrwjZMSJIkVYRhIqOsTCxMcifsAyeH3LxOkiSpAgwTGeUeEwuzvqOZtqZC6Boen+TEwFjKI5IkSco+w0RGle8xYZiYSwihrG/iwMnBFEcjSZJUGwwTGTU4mqxMOM1pPi5OTHV68oRhQpIkaakMExlVvs+ElYn52Laho/T8iROD9k1IkiQtkWEio8oqEy1WJubjwjVttDQW/it/dnicAydd1UmSJGkpDBMZZWVi4XINgUvWTS8R+60nTqY4GkmSpOwzTGTUYCJMWJmYv20bpsPE/Y8bJiRJkpbCMJFRQ4lpTlYm5u+yRN/Etx4/ad+EJEnSEhgmMqqsMuFqTvO2aXVrab+JEwOjPH58IOURSZIkZVcmw0QIYXMI4aMhhMMhhNEQwv4QwvtDCN0LPM/a4vf2F89zuHjezec4/pdDCH8VQvh6CKEvhBBDCP+jMj/VwgwlNq1zn4n5awiBS9c71UmSJKkSMhcmQgiXAQ8BrwEeBP4SeAJ4G/CtEMK6eZ5nHfCt4vceL57nweJ5HwohbJvla38IvBm4Bnh6aT/J0gyOWplYrGTfxLcME5IkSYuWuTABfBjYCLw1xnh7jPH3Y4w/QyEMXAm8d57n+WPgCuB9Mcbbiue5nUK42Fi8zky/U/xOF/BbS/w5lqSsMmHPxIIk95v49hMnyeftm5AkSVqMTIWJYlXixcB+4EMzPn4XMAi8OoSwivMIIXQAry4ef8eMjz8IHAB+bmZ1IsZ4X4xxX6yCrt2BUVdzWqyezpZSNef00DiPHelLeUSSJEnZlKkwAbyw+HhPjDGf/CDG2A98E2gHbprjPDcBbcA3i99LnicPfGHG9apO/8h0mOhqbUpxJNkTQuCyjdPVift296Y4GkmSpOzKWpi4svi49xyf7ys+XrFC51mUEMJDs/0Ddszn+/l8pH9kvPS6s9VpTgu1Y1NX6fmXDBOSJEmLkrUwsbr4ePYcn0+9v2aFzpOKwbEJpqb5r2rO0ZjL2q8xfVf2dJJrCAD84Kkz9PaPpDwiSZKk7PEuNAUxxutn+wfsns/3+xJTnDqd4rQobc05brh4eiVhpzpJkiQtXNbCxFTFYPU5Pp96/8wKnScVfcPTU5y62pzitFg/u7On9PxLuwwTkiRJC5W1MLGn+HiuXobtxcdz9UJU+jypKAsTViYW7badG0vPv7HvBCPjk+c5WpIkSTNlLUzcV3x8cQihbOwhhE7gFmAI+PYc5/k2MAzcUvxe8jwNFJafTV6vqiSnOXW1GSYWa9uGjtJu2MPjk3zrCTewkyRJWohMhYkY4+PAPcAlwJtmfPxuYBVwV4xxcOrNEMKOEELZKkkxxgHgruLxd8w4z5uL5/9CjPGJCg6/YsorE05zWorbdkxXJ+7ddSzFkUiSJGVPFu9E3wjcD3wghHAbsAu4kcKeEHuBP5hx/K7iY5jx/juAFwBvDyFcAzwI7AReDvTyzLBCCOF24Pbiy03Fx5tDCB8vPj8RY/y9Rf1UC9A3kuyZsDKxFLft7OEj33gSgHt39fKeX4g0NMz8r4okSZJmk7kwEWN8PIRwA/Ae4CXAS4EjwJ3Au2OMp+d5npMhhJsp7Jx9O3ArcBL4GPDOGOOhWb52DfDrM97bVvwHhZ2zlz9MDLthXaXccEk3a9qbODM0zpGzIzy4/xQ3bVuX9rAkSZIyIVPTnKbEGJ+KMb4mxnhBjLE5xnhxjPG3ZwsSMcYQY5z1T80xxlMxxrcVv99cPN9rzxEkiDHeMXW+c/y7pMI/6qz6R1zNqVKacg287NkXlF5/+ntPpzgaSZKkbMlkmKh3ZdOcrEws2S9ed1Hp+ed+eMRVnSRJkubJMJFByWlOblq3dNdt7ebide0A9I9McK97TkiSJM2Lc2Qy5u4HDrK3t7/0+rsHTnE2sbqTFi6EwO3XXMSd9+4D4FPfe5qXXX3BHN+SJEmSlYkMSk7DaWvKpTiS2vGKa6enOn1lTy+nBsdSHI0kSVI2WJnIoJHxfOl5q2Fi0e5+4GDZ6y3dbTx1epiJfORd//IoNxdXdXrVjVvTGJ4kSVLVszKRQcNj05UJw0TlXLu1u/T8u/tPEWNMcTSSJEnVzzCRMTHGsmlOrU3+Civl6s2racoVVhE+cnaEAyeHUh6RJElSdfNONGPGJvJM/b28KRdobPBXWCntzY1cs2VN6fX9T5xMcTSSJEnVzzvRjBm2+XpZ3bxtfen5Y4fPcmbIRmxJkqRzMUxkzMiEzdfLadPqVratXwVAPsIDT55KeUSSJEnVyzCRMSM2Xy+75142XZ148MlT7ogtSZJ0DoaJjLH5evntuKCT7vbCzuLD45P8r4efTnlEkiRJ1cm70YwZHrcysdwaQuCm4h4TAH/91R8zPpk/zzckSZLqk2EiY9z9emU855K1pf98nzo1zGe+fzjlEUmSJFUfw0TGDLv79YpoacrxvO3TvRMfuu/HTFidkCRJKmOYyBgrEyvn5m3rSn0pT54Y5LOPHEl5RJIkSdXFMJExI/ZMrJjWphy3JFZ2+qsv72MyH8/zDUmSpPpimMiYYVdzWlHPvWw9nS2NADx+fJB/+6HVCUmSpCnejWaM05xWVltzjv90yyWl13/15X3krU5IkiQBhonMGbEBe8W99pZLWdVc+M9677EBvvDo0ZRHJEmSVB0MExljz8TK617VzK8995LS6zvvtTohSZIEhonMsWciHa9/3qWlaWW7j/bzpV3HUh6RJElS+rwbzZAYo5WJlKzraOHVN19cen3nvfuI0eqEJEmqb41pD0DzNzw+ydTsmsaGQFPOLLgS7n7gIADrVjXTlAuMT0YePdzHH336Ua66sKvs2FfduDWNIUqSJKXCu9EM6RueKD13JaeV19naxI2Xriu9vnf3MasTkiSprhkmMqRvZLz03ClO6bh1+3qacgGAI2dHeOxIX8ojkiRJSo9hIkP6hpNhwl9dGjpbm7hpW6I6sauXvNUJSZJUp7wjzZBkZaKt2cpEWm7dvoHmYr/K0b4RHj1sdUKSJNUnw0SG9I9M90w4zSk9HS2N3HzZdHXiS7uOMem+E5IkqQ4ZJjKkbJpTo2EiTbdevp6WxsL/fI73j/K9g6dTHpEkSdLKM0xkSJ+ViarR3tLIrds3lF7fu7uX8cl8iiOSJElaeYaJDElWJtpswE7dLZevo6OlsFXL2eFxvv3EyZRHJEmStLK8I82Qs4kw0WJlInUtjTleuGNj6fVX9hwv+x1JkiTVOsNEhpwYGC09n/qLuNL1U5d0s3ZVM1DYofyDX96X8ogkSZJWjmEiQ3r7p8NEZ6thoho0NjTwop09pdcf/eZ+dh91qVhJklQfDBMZ0tuXDBNNKY5ESVdvXs2l61cBMJmP/OGnfkTepWIlSVIdMExkRD4fOT5gZaIahRD4hZ+8kIZQeP3dA6f554cPpTsoSZKkFWCYyIiTg2OljdHamnI05fzVVZOerlaed/n0UrF/8m+7OJkIf5IkSbXIO9KM6O0fKT23KlGdfmbHRi5a0wbA6aFxfu///QExOt1JkiTVLsNERth8Xf2aGxt47yueVXp9357j/PdvPJniiCRJkpaXYSIjjiear7tsvq5aL7hyI69/3qWl13/2+d388NDZFEckSZK0fAwTGeE0p+z4P16yg2dftBqA8cnIm+5+mNODYymPSpIkqfK8K82IYy4Lmwl3P3AQgBdf1cOeY/2MTeQ5eGqIV3z4fl57yyU0FhvnX3Xj1jSHKUmSVBFWJjLCykS2rOto4Zev21x6vf/kIJ/+/tM2ZEuSpJpimMiI8gZsKxNZ8KyLVvNzV03vjv3wwTN8Ze/xFEckSZJUWYaJjOgta8C2MpEVP33FBq7f2l16/cXHjvHgk6dSHJEkSVLlGCYyIMbIcSsTmRRC4OXXXsi2DatK733m+0/zbz88kuKoJEmSKsMwkQFnhsYZm8wD0NLYQHOjv7YsaWxo4FdvvLi0oV0E3vbJ7/GVPb3pDkySJGmJvCvNAPslsq+1KcevP/cS1ne0AIUlY3/jroe4z0AhSZIyzDCRAa7kVBs6Whp57S2XsKa9EAjHJvL85ice4r7dBgpJkpRNhokMKN9jwjCRZWvam/nPz9vG5u7ClKexyTy/eddDfPp7T6c8MkmSpIUzTGRAsjLR5TSnzOte1cwnf+MmtqydDhS//Y/f5/1f2us+FJIkKVMMExnQa2Wi5mzubucff+NmrujpKL33/i/t422f/D4DoxMpjkySJGn+DBMZ4LKwtenCNW388289l1u3ry+99y8/OMzPf+Dr/PDQ2RRHJkmSND/+mTsDbMCuPXc/cLD0/MVXbWJkPM939hc2s9t/cojbP/RNXnRVDx/6364j1xDSGqYkSdJ5WZnIgGNlu19bmag1uYbAK669iP9ww+bSHiKTMfL5R4/yK3/7LQ6cHEx5hJIkSbMzTFS5GKOViTpxzZZu3vLCy0srPQF8Z/9p/t2dX+fuBw7anC1JkqqOYaLK9Y9OMDJe2P26rSlHi7tf17R1HS385k9fxm07NjI1u2lobJJ3fOqHvObj3+FY38j5TyBJkrSCvDOtcsmVnDZ2tRCC8+drXa4hcNvOHt7w/Mu4fOP0ak9f2XOcF//l1/jcI0dSHJ0kSdI0w0SV6038JbqnszXFkWilbe5u57NveR6ve96lTGXIs8PjvOnuh3n7P32f/pHxdAcoSZLqnhPwq9yxRL/Ehq6WFEeiNPyvh5/msg0dvO6WS/nnhw5xZni89P59u3v55eu3cOn6VQC86sataQ5VkiTVISsTVW7P0YHS84vXtqc4EqVp24YO3nrbdq7dsqb03umhcT7y9Se459GjTOTzKY5OkiTVK8NElXv08PTmZT9x4eoUR6K0tTbleOUNW/iVn9pCa1Phf7oR+Mre43z4vsd5+ODpdAcoSZLqjmGiisUYeexwX+n1T1zYleJoVC2u3ryGt912Bds2rCq9d7RvhF/66/v5o0//iD57KSRJ0goxTFSx3v5RTg6OAdDR0shWpzmpaHVbE6+95VJe9uwLaMoVurNjhLu+fYCf/Yuv8v/98Ij7UkiSpGVnmKhiyarEzgs6aWhwWVhNawiBWy5fz2/fdgVX9EwvIdvbP8pv/f3DvP7vvuvu2ZIkaVkZJqpYsl/iqguc4qTZda9q5tdvvoQPvupaNnROr/h17+5eXvS+r/Fnn9/NwOhEiiOUJEm1yjBRxR47kuyXsPla5xZCoG94gjf89GU855K1pffHJvP89Vce58Y/vpc33/0wn7h/f3qDlCRJNcd9JqrYo4lpTlfZfK15aGvOcfu1F3H9xd189pHDPHV6GIDB0Qk++8gRvrHvBAT4pes2s6rF//lLkqSlsTJRpfpHxjlwcgiAxobA9sSceGkuW9a285vPv4xXXr+Z1W1NpffPDI/zzs88yk1/ci/v+dfHeOTQGRu1JUnSovmnySq160h/6fnlGztoacylOBplUUMIXLu1m2ddtJoHnzzFV/b0Mjg2CUD/yAQf/eaTfPSbT3LRmjZedFUPN21bx42XrqV7VXPKI5ckSVlhmKhSj7lZnSqkKdfALZev54ZLunn4wGl+dLiPJ09Mr/L09JlhPn7/fj5e7KfYsamTm7at46Zta3nOpetYa7iQJEnnYJioUvZLqNJaGnPcfNl67vyVa/nqvuP86w8O86XHjtE3Ur7S0+6j/ew+2l8KF1f2dHLjtrXctG0dz7l0Les7WmY5uyRJqkeGiSpVvpKTYUKV88nvPAXADRev5dot3TxxYoAnjg/y5IlBDp0eIj+jhWLPsX72HOvnE986ABTCxW07N/Kiq3r4yc1r3P9EkqQ6ZpioQmMTefYdGyi93ukeE1omuYbA9o2dbN/YCcDoxCQHTw7x5IlBnpgjXHz4K4/T2dLIjgs6ecPzL+OWy9fT2mRvjyRJ9cQwUYW+vLuXsck8AFvWtpWtxiMtp5bGHNt7OtneUwgXYxN5Dp4a4okTA4XKxalhJhOrP/WPTvCd/af5zv7v0taU49bt6/nZq3r4mR0bnQ4lSVIdMExUoY9+48nS839/9YUpjkT1rrmxgcs3dnD5xsLSxGMTeX7cO8CuI33sPtpXWh0KYHh8knseO8Y9jx0jBLh+azcvuHIDP3HRaq66oIuNnS2E4JQoSZJqiWGiygyPT/Lg/lMANOUCv/7cS9IdkJTQ3NjAVRd2cdWFXeRj5KlTQ+w60sfTZ4Z5/Pj0ClExwncPnOa7B05PfzfXQGdrI52tjXS1NRUeW5voXtXM2vZm1nc0s7m7nS1r29myto32Zv/PkyRJ1c7/b11lTgyM0l58/vNXX0hPV2uq45HOpSEELl63iovXrQLgRP8ou472setIHwdODjFzK7yxyTwnB8c4OTg2r/OXhYvuNjZ3t9Pd3sTqtiY6WhvJNQQaGxqKj4FcQ2Cq8BFCIAAhQC4EWptztDXlaMq5T6ckSZWUyTARQtgMvAd4CbAOOAJ8Gnh3jPH0+b474zxrUGLFGQAAFpxJREFUgXcCtwMXACeBzwPvjDEeWs5rn8vZ4fFSmHjd8y5d6umkFbO+s4VbOzdw6/YNDIxOsPdoP0+dHuLo2RGO9o0wOpFf0PlODIxxYmCM7z91pmJjbG/OsWl1K5u6Wrl43Sq2b+xge08H2zd20tPlNCxJkhYqc2EihHAZcD+wEfgMsBt4DvA24CUhhFtijCfncZ51xfNcAXwZ+CSwA3gN8LIQws0xxieW49rnVfxz7o2XruVZF7lZnbKpo6WR6y7u5rqLu0vvjU/mGRmfZHh8ktHxPMPF50NjkwyNTtA3MsHpoTFOD45xZmi8rNG7Uob+//buPE6Oss7j+OfbM5NJSCAQlhs1giCuCq64crmSEEUQEBTwxnCtIAIiuuuCB8FzvRG89rWuZgUVXZRFWRQ0EM4FhCjKChKOcChIJJCEnDPTv/3jeTqpdLrn6OmZnul8369Xvar7qaqnnup6pqZ+VfXUs7aPBxev4MHFK7jlgQ3/VDef2Mmu20xhpy0nsf3UiUybPIGJXR10d5bSkD93lkRJolQSpXznQ0p3RkqCiV0dTOnuZHJ3eqSru7PkIMXMzNrWuAsmgK+TTubPjIiLKomSvgS8H/gUcOog8vk0KZD4UkR8oJDPmcBX8noOGaF1D8h3JazddHWU6OoosfnEgd9OVo5g2aoelqxcy9Mrenh65VqWruxZF4Cs6e0jAvrKQTnS/OUIiHXxOJGDkb6A3r4ya3vLGz16VbR8dS+/ffSZpt4JgfT63SndneuGyd0d6wKNyRM6mTKxOC2lVz5PKXzv6qz9iFa/MVc/06LfXwM6O0pM6CjR1SEHQ2ZmVpdiBK7+jZR8Z+B+YBGwa0SUC9M2Jz1yJGDbiFhRM5M07xTgSaAM7BARywvTSsCDwPPyOh5s5roH2L47J2y368vfMOe7XPru/eio0RnY9297pJGszTZ5EcHqnjJLV/WwdNVaFi9fw5PrhtWs7hnaY1ibkq4OpcCiMwWEEzpKTOjMwUanNkhLd3LyHZ2uwufC3Z3unE9vOejtK6dx/tzTF/SVg55ymd7K5770uadcpq8c6XNfOc9XyKOvTF9AVymVqauzUi6tC2bXlbtD6753FQKnCZ0ddOb2N1K62ySlNkKQxiUppwFU5lk/ryrz5PlVSc/zlnI7n4ldHXkoMbGzgwmdJYJUV8uxftzbV2ZNb5m1OShe05vGa3vLrO3r2yAtYn15S6XK+vN6VSyr6Cit/9yZy9TVWaKrlPZrZyn9Lp0dojPXgc7Kb1cqUSqJiLSPivuwN++j3ry/UtCftqXyWWz8u6jq96y0e6r89pXPxWXIn1Ma6wLfyrJKM2wwvThtfTurPC6kVasXUtcLtuvP3/9yZqNl7733ZsGCBQsiYu/h5DPe7kzMzONriifzABGxXNLNwMHAvsC8fvLZF5iU81lenBARZUlXA+/O66s86tSsdfdr6mZdfPfEfWoGEmbWOElMmtDBpNxu4oXbr58WESxf3ctfV6xh2aqefBekvO6EtniyWo50VT/yHZE0TmnlfEK1uqePNfkEr6+6179xqKcv6Onrg8KrgM1KYqNOLa0x/QZDOUEbzFsIhKqW23De+oEWhTw+e/RLOWiP7UZuA62tjbdg4oV5fF+d6QtJJ/S70/8J/WDyIefT7HUj6c46k/Z69omHedV+r6y77JJBvgnHzMaOiA2DjwgoU51WuBrNxlenW1VuM2t/p3xvM7ZwB7mbnHvuuQdg+nDzGW/BRKVF8tI60yvpW45APs1ad39Kq1at6luwYMFdw8jD2sMeeXxvS0thY4HrglW4LhiMQD24/y/NyslG2XDrwnRg2XALMd6CibZQ79m0yh2L4T67ZuOf64JVuC5YheuCgeuBrTdW6sJ468GpcvW/3jtTK+kDvY6lkXyatW4zMzMzs7Yw3oKJP+bx7nWm75bH9do1DCefZq3bzMzMzKwtjLdg4ro8Pji/wnWd/HrWA4CVwK0D5HMrsAo4IC9XzKdEakhdXF8z121mZmZm1hbGVTAREQ8A15AajLy3avL5wGTg4mI/D5L2kLRHccaIeBa4OM8/pyqf03P+Vxd7wG5k3WZmZmZm7Ww8NsA+DbgFuFDSLOAeYB9SPxD3AR+umv+ePK7uuOFcYAZwtqSXAbcDLwKOJHVoVx0wNLJuMzMzM7O2Na56wK6Q9Bzg48AhwNak3qcvB86PiKer5g2AiNioFzhJ04DzgKOAHYCngJ8DH4uIx4a7bjMzMzOzdjYugwkzMzMzM2u9cdVmwszMzMzMxg4HE2ZmZmZm1hAHE2ZmZmZm1hAHE2ZmZmZm1hAHE2ZmZmZm1hAHE2ZmZmZm1hAHE2OApJ0lfVvSnyWtkbRI0gWStmp12az58v6NOsMTdZbZX9JVkpZIWiXpd5LOktQx2uW3oZF0jKSLJN0oaVnez5cMsMyQ97ekwyXNl7RU0rOSbpM0u/lbZI0aSl2QNL2f40RIurSf9cyWdHuuB0tzvTh85LbMhkLS1pJOlnS5pPvz3/hSSTdJOklSzXMzHxfay1DrwVg+JozHHrDbiqRdSb1qbwtcAdwLvBJ4H3CIpAMi4qkWFtFGxlLgghrpz1YnSDoS+DGwGvghsAQ4AvgycABw7MgV05rgI8BepH37GLBHfzM3sr8lnQ5cROp48xJgLXAMMFfSSyPig83aGBuWIdWF7C7gv2uk311rZklfAD6Q8/93YALwVuBnks6IiK82UG5rrmOBb5A6vb0OeATYDngT8C3gUEnHRqEjMB8X2tKQ60E29o4JEeGhhQNwNRDAGVXpX8rp32x1GT00fZ8vAhYNct4tgCeBNcArCukTSUFoAG9t9TZ56HcfzgR2AwTMyPvskmbtb2A66QTjKWB6IX0r4P68zH6t/h08DLkuTM/T5w4h//3zMvcDW1Xl9VSuJ9OHsw0emlIPDiIFAqWq9O1JJ5QBHF1I93GhDYcG6sGYPSb4MacWynclDiadXH6tavJ5wArgOEmTR7loNnYcA2wDXBoRd1QSI2I16SonwHtaUTAbnIi4LiIWRj6CD6CR/X0i0A18NSIWFZZ5Gvh0/npqg8W3JhpiXWhEZT9/Ku//ynoXkf7HdAMnjNC6bZAi4tqI+FlElKvSnwC+mb/OKEzycaENNVAPGjEqxwQHE601M4+vqVGZlgM3A5sB+452wWzEdUt6p6RzJb1P0sw6z70elMe/qDHtBmAlsL+k7hErqY2mRvZ3f8v8vGoeG392lHRKPlacImnPfuZ1XRj/evK4t5Dm48Kmp1Y9qBhzxwS3mWitF+bxfXWmLyTdudgdmDcqJbLRsj1wcVXaQ5JOiIjrC2l160hE9Ep6CHgxsAtwz4iU1EZTI/u7v2Uel7QC2FnSZhGxcgTKbCPrtXlYR9J8YHZEPFJImwzsBDwbEY/XyGdhHu8+QuW0YZLUCbwrfy2e/Pm4sAnppx5UjLljgu9MtNbUPF5aZ3olfctRKIuNnu8As0gBxWTgpcC/kZ5h/LmkvQrzuo5sWhrZ34NdZmqd6TY2rQQ+AexNes59K+BAUkPNGcC8qkdgfawY//4VeAlwVURcXUj3cWHTUq8ejNljgoMJs1EWEefnZyX/EhErI+LuiDiV1Oh+EjCntSU0s1aLiCcj4mMRsSAinsnDDaS71bcBLwBObm0prVkknUl64869wHEtLo61SH/1YCwfExxMtNZAVwYq6c+MQlms9SoNrl5dSHMd2bQ0sr8Hu0y9q1M2jkREL+m1keBjRVvIr3D9CvAHYGZELKmaxceFTcAg6kFNY+GY4GCitf6Yx/WeV9stj+u1qbD2sjiPi7cp69aR/Fzl80kNtB4c2aLZKGlkf/e3zA6k+vSYn4tuKxsdKyJiBfAnYEre79X8/2QMknQWqS+Iu0knkLU6LvVxoc0Nsh70p6XHBAcTrXVdHh9co6fDzUkd0awEbh3tgllLVN7aVfyHcG0eH1Jj/leT3vZ1S0SsGcmC2ahpZH/3t8yhVfNYe6h1rADXhXFF0odInc79lnQC+WSdWX1caGNDqAf9ae0xYbgdVXgYdqcl7rRuExqAFwGTa6RPJ71ZIYBzC+lbkK44uNO6NhgYXKd1Q9rfpKuS7pxqnA2DqAsvp6ozq5w+K+/vAPavmuZO68bJAHw076s7gGkDzOvjQpsOQ6wHY/aYoJyptUjuuO4WYFvgCtJr3fYh9UFxH6liPNW6ElozSZpDalx1A/AwsBzYFTiM9I/hKuCNEbG2sMxRwGWkP/pLgSXAG0iv/rsMeHP4D3nMyvvvqPx1e+B1pKtHN+a0v0bEB6vmH9L+lnQGcCHpn8MPgbWkjq52Br5YzN9aZyh1Ib/qcTfS/4fH8vQ9Wf9O+I9GxCdrrOOLwNl5mcuACcBbgK1JF62+2tytsqGSNBuYC/SRHm2p1W5hUUTMLSzj40KbGWo9GNPHhFZHZR4C4Dmk14U+Tvpjfxi4gEIU6aE9BtJr3H5AelPDM6SOaRYDvyS9V1p1ljuAFGg8DawCfg+8H+ho9TZ5GHCfzyFdGao3LGrG/gaOAK4nBagrgF+T3jve8t/Aw9DrAnAScCWwCHiWdFX6EdJJ4T8MsJ7j8/5fkevD9cDhrd5+D4OuBwHMr7GcjwttNAy1HozlY4LvTJiZmZmZWUPcANvMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzMzMzBriYMLMzGwMk7SnpBWSrpLU2erymJkVOZgwM2sDkkLS/HZb10iTdHzenuNbXZZaJE0Ffgz8DjgmInpbXCQzsw04mDAzG6PySW60uhxjiaQ5+XeZ0eqyjDRJAi4GeoDDImJli4tkZrYR3y41M2sPLwJ8stleXgAsAN4bEUtaXRgzs1ocTJiZtYGIuLfVZbDmioiFwJxWl8PMrD9+zMnMrA3Ua8cgqUPSqZJulrRU0ipJ90v6lqTd8jwzKo9U9TPMqJH3jpIulvRkzvdOSW+vMd8ESafnBsQPS1ojaYmkX0k6dAjbuAg4L3+9rli+qvl2kPQ1SYskrZW0WNJPJO09hHVtJekGSWVJ5xTSOyWdJulWScskrZT0m7x9pao8pufyzc2fL5X0V0mrJd0h6fA66+6W9C+Sfp/zXybpRklvrppvSt6+m6vSJ+V1hKTjqqa9J6efONjfwsysP74zYWbWpiRNAK4EXgs8CnwfWAZMB94I3AQsBBYB59fIogs4G5jIxo9QbQXcAjwDfAfYEngz8D1JO0XE5wvzTgO+kuf/JbAY2AE4ArhK0j9GxLcGsUkXAEcBBwL/mctdvc3Pz9u1I3At8APgOcCxwGGSjo6IK/tbiaTnAr8gPWb0roi4JKd3AT8DXgf8kfR7rgZmAhcB+wDH1cjyecDtwIOkNhDTgLcAV0h6TURcV1j3BODqvI33Al8DNgOOAX4o6WURcS5ARDwr6XZgH0mbR8TynM0BQHf+PCuvk8J3gHn9/QZmZoMWER48ePDgYQwOQKTD9KDnnV+V9umc/lOgu2paN7DNAHnOzct/uVa5gB8BpUL684ElwFpgl6p17Vwj/6nA3XmZSYPczjl53TPqTL86T/9wVfr+QC/wFDClkH58nv/4/H0v4M/AUuA1ddZ9EdBRSO8A/iNPO7KQPr3wW51XldfrcvpVVennVNKBzkL6tqTgKYD9C+kfz2mHFdI+k7d1HvBoIb2Ut/+BVtdtDx48tM/gx5zMzNqQpA7gNGAVcGpErClOj4g1EbG4n+U/BswGrgA+UGOWPuBDEVEu5PkQcCHpjsZxhfQ1EfFYdQYRsRT4Nukux98Pfuvqlnln4GDgEeBzVeu6hXSXYhrwpjrLvxa4kXRy/uqI+FVhWgk4A3gCeH9E9BXy7iP9RgG8o0bWDwOfrCrP1bmcr6ya98Scz9lReA1sRDwJfCJ/Pbkwf+UOw6xC2izgTuAnwM6Sds/pLyNtv+9KmFnT+DEnM7P2tAfpyv9tEfHnoSwo6R2kx57uAN5eDBgKHsnBQ7X5pHYNf1eV54uBfwJeTXrEaWLVcjsNpYx1VNZ5Y0T01Jh+LfDOPN93q6YdQwpEFgKHRsQjVdN3J52ILwQ+kt7aupFVpLdqVfttMfgoeBTYr/JF0uakR6v+FLUb1F+bx8Xf9n/zemflPKYCLycFU5X5ZwH3AQdV5WNmNmwOJszM2tOWefynoSwk6UDS3YKHgcOjft8Gf6mT/kQeTy3kuS/pBLaTdFX8p6S2G2XS1fIjWf+M/3BU1vl4nemV9C1rTNuPdEflNtJJfrWt83g31jcCr2VKjbRn6szby4YvQhly+SNiraSbgNdI2ob0OFcHMC8i7pH0OCmY+EYeBw4mzKyJHEyYmbWnygnsoK/4S9oDuJx0pfv1EVEvYADYrk769nm8tJD2EWASMDMi5let8xxSMNEMlXVuX2f6DjXKVnEu8HrghFQsnVR1R6ayzOURUfMxqSZotPzXkhrZzyIFE6uBmwvTDpXUDfwD8H/5kSkzs6Zwmwkzs/Z0Lymg2FPSjgPNnK9q/w/pyvrREfGHARZ5rqTpNdJn5PFvCmkvAJZUBxLZgQOVrUrlcaGOGtMq63yVpFoXy2bm8YIa09aQHnX6L1Kj7Euq8qj8nvvmtzo1XaS3MT0A7FR5bW+VeuUvtps4CLglIlYXpk0D3gNMxu0lzKzJHEyYmbWh/Iz+10l3BL6Zr0yvk/t+2CZ/nkh69GgX4JSIGMwJZwfw2WLfCvm1rGeSHt+5pDDvImCapD2rynAS6a1GQ/FUHj+3ekJu5P1L0luUzqpa1z7A24GnSXdfNpLbWbwtl/1tpFexduVpvaS3OO0AXChpUvXyuX+Lvx3i9lT7NiDg87kRfSXvvwE+WpinaAHpbsWRwIvZMGCoPNJ0TtV3M7Om8GNOZmZjnKS5/Uw+rZ92DeeT+j44ArhP0pXAclK/CweTGkTPJQUA+5L6QXiepDk18pobEYsK33+X875T0jWs72diS+CfI+KBwrwXkIKGmyT9iHTi+wrgVcBlpDsCg3Udqa3FZyS9hBQcEBGVtyWdSnrE5/OSDiY1Iq/0M1EGToj1/TFsJCL6JM0mPSp0MvATScfkt2F9gvTq2FOBIyRdS2qTsi2pLcUBwIeBge7q9OcLwKGkwOAuSVeR+pk4Nq/ncxFxU40yz2f942LzCtMelvQAsCvprs71wyibmdlGHEyYmY19s/uZdhYbdygHrGucewjp5PddOR+R+lG4nNS5G6STVUh3Juo1Lp7Php3EPU066f0cqZ3BFqST6C9ExPeryvELSUeQ2k68hXRSezvpsZ1dGEIwkRsVzwY+SHr1beWtUJ/M0x+U9Iq8rteTHrtaRuqE7lMR8etBrKMs6d2kgOJ04KeSjoqIVZKOIr0R6njgcNJjYYuBh0h3Dr432G2ps+61+RW1Z5PupJxButNzF3BWRPygzqLzSMHEMlIAVT1tV+DO/DpeM7OmUUS0ugxmZmZmZjYOuc2EmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk1xMGEmZmZmZk15P8BO6XEAS+5accAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "image/png": {
              "width": 393,
              "height": 261
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 75\n"
      ],
      "metadata": {
        "id": "cvV8y8YFR-2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "\n",
        "  def __init__(self, text, targets, tokenizer, max_len):\n",
        "    self.text = text\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.text[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'text': text,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "LxZNzvFLSWGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "6q3k9LdkSWIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqELaETTSWKl",
        "outputId": "920dca47-880a-4b9a-8dbf-583e1fe0e5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24296, 2), (1350, 2), (1350, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = TextDataset(\n",
        "    reviews=df.text.to_numpy(),\n",
        "    targets=df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "metadata": {
        "id": "uWoexpyaSWM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=16\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O89Z-HNqSWPU",
        "outputId": "7b7d3e08-ea6f-413f-e005-fa5345e56fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B06ZtMQ0Iivs",
        "outputId": "bac9a38f-9832-491d-926a-d8864db4f222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd6a85e2150>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZjxBjSw4Nbh",
        "outputId": "f1afbcd7-78b7-454c-f045-852bddc35c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd6a8353d10>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SKaBu44m4RBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOgWYDC2SWRt",
        "outputId": "ba7f198c-fc66-4fd0-bd31-a833c87a4348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBuXVUh3SWT8",
        "outputId": "b74e87c1-7d71-46e5-ac0c-7d492039e3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 75])\n",
            "torch.Size([16, 75])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME,return_dict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3MRuBbSSWWG",
        "outputId": "af70739c-6803-4f5b-cd92-2588808acbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "metadata": {
        "id": "LhCUdT4rSWYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bP5arpsR-4Y",
        "outputId": "f3d426b7-82af-44d9-e158-e480b7cde17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHiTO-ZBR-6n",
        "outputId": "0f8b62d0-8c0f-4307-cd25-586f7e6b57fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdMYYj3UUVxu",
        "outputId": "e6c5742c-5d1c-4535-b96c-9e851fad5e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME,return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "6erUHIN6UVva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['negative','positive']"
      ],
      "metadata": {
        "id": "Nqp2fPO9UnWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkiqQs0LUVtH",
        "outputId": "4da0bdf9-5712-4d79-a853-36f5a7641e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD-j9kegUVq3",
        "outputId": "b59d5ab2-0664-42bf-bf36-873610e0f30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 75])\n",
            "torch.Size([16, 75])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxL0msJhUVoy",
        "outputId": "3c1d36ae-9247-49b1-9d1b-da210ebbb3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5490, 0.4510],\n",
              "        [0.4127, 0.5873],\n",
              "        [0.6376, 0.3624],\n",
              "        [0.4119, 0.5881],\n",
              "        [0.5756, 0.4244],\n",
              "        [0.5164, 0.4836],\n",
              "        [0.4750, 0.5250],\n",
              "        [0.4614, 0.5386],\n",
              "        [0.4688, 0.5312],\n",
              "        [0.4140, 0.5860],\n",
              "        [0.4286, 0.5714],\n",
              "        [0.5137, 0.4863],\n",
              "        [0.4827, 0.5173],\n",
              "        [0.5824, 0.4176],\n",
              "        [0.5290, 0.4710],\n",
              "        [0.5594, 0.4406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAgTT8UtUVmY",
        "outputId": "92c6d384-6840-401a-bca9-d077bc1c4d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "V1qEDuxcUVj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "DIX9gGzgUVhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9BSz-0VVlQV",
        "outputId": "7453a16f-d72c-448f-9647-1198b6b194e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2794851076061432 accuracy 0.8927807046427395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.22434436704086907 accuracy 0.9155555555555555\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11980186043983299 accuracy 0.9656733618702666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.37979713247760255 accuracy 0.9207407407407407\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05772694606558371 accuracy 0.986746789594995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5022625271780485 accuracy 0.9133333333333333\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.029824277854480025 accuracy 0.9933733947974974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5212682929127956 accuracy 0.9177777777777777\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013260149028336986 accuracy 0.997324662495884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6260822684844778 accuracy 0.9177777777777777\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013110151284847086 accuracy 0.9975716167270332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6517704543894284 accuracy 0.9177777777777777\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.005278449239799907 accuracy 0.9990121830754033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7423981140304343 accuracy 0.9133333333333333\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.007500210412067426 accuracy 0.9987240698057293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6702898136494161 accuracy 0.9185185185185185\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.002754502429502865 accuracy 0.9993826144221271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7476776034539452 accuracy 0.9162962962962963\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0008231611790712546 accuracy 0.9998353638459005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.764919827407801 accuracy 0.9125925925925925\n",
            "\n",
            "CPU times: user 28min 40s, sys: 7min 55s, total: 36min 36s\n",
            "Wall time: 37min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =SentimentClassifier(len(class_names))\n",
        "model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUENhzjrVlLF",
        "outputId": "0332b604-06c0-42f5-e2e6-b3556dfd83e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(60000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "BKARl1PNVlEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8te1Y-6y3Eif",
        "outputId": "34a2b386-b343-4525-e160-3c2726f375e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwitP_kB3EpW",
        "outputId": "c1007c67-73e5-406a-8ebe-ba599ff99a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.95      0.92       749\n",
            "    positive       0.93      0.86      0.89       601\n",
            "\n",
            "    accuracy                           0.91      1350\n",
            "   macro avg       0.91      0.90      0.91      1350\n",
            "weighted avg       0.91      0.91      0.91      1350\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Sentyment')\n",
        "  plt.xlabel('Przewidziany sentyment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "QOUgR8Qq3Er0",
        "outputId": "e4b464af-9255-460b-c6bf-d5163996c37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 400,
              "height": 282
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw=\"\"\n"
      ],
      "metadata": {
        "id": "6lTuawTj5d-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_raw = tokenizer.encode_plus(\n",
        "  raw,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajb9jKIG5jDb",
        "outputId": "9323473c-8c6a-4641-bec7-311d79b6aad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = encoded_raw['input_ids'].to(device)\n",
        "attention_mask = encoded_raw['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Raw text: {raw}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ppx_0w75mlN",
        "outputId": "b8374d71-5a70-4dce-8811-471449249997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text: Oby ci matka zdechła na tym midlejnie\n",
            "Sentiment  : negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.read_csv('Polarity.csv')"
      ],
      "metadata": {
        "id": "x6fgPFW05xKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "OT1BhwQCRcGm",
        "outputId": "bb177463-8ddf-4c50-af2f-57ef01dd6e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               Text  \\\n",
              "0              0  #pis #PolskiŁad Trybunał Konstytucyjny od kuch...   \n",
              "1              1  Wiecie kiedy pisowiec mówi prawdę? Kiedy się p...   \n",
              "2              2  To po co występowaliśmy o derogację do UE  \\n@...   \n",
              "3              3   Przeca żeś bogaty, skoro Polski ład Ci zabiera!    \n",
              "4              4  Polski Ład? A dziękuję, nie narzekam. No może ...   \n",
              "...          ...                                                ...   \n",
              "3048        4009  No to jest Pan ciekawym przypadkiem „wierząceg...   \n",
              "3049        4010  Wyluzujcie z tymi korzyściami. Już Polski Ład ...   \n",
              "3050        4011  A PiS jaki ma program? Pytam w zakresie podatk...   \n",
              "3051        4012                                         5\\n10\\n142   \n",
              "3052        4013  Jakub Chełstowski\\n@JakubChe\\n · 2 mar\\nZarząd...   \n",
              "\n",
              "      Subjectivity  \n",
              "0              0.0  \n",
              "1              0.0  \n",
              "2              0.0  \n",
              "3              0.0  \n",
              "4              0.0  \n",
              "...            ...  \n",
              "3048           0.0  \n",
              "3049           0.0  \n",
              "3050           0.0  \n",
              "3051           0.0  \n",
              "3052           0.0  \n",
              "\n",
              "[3053 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43b9878d-640a-465a-836b-def2ff24ed3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>#pis #PolskiŁad Trybunał Konstytucyjny od kuch...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Wiecie kiedy pisowiec mówi prawdę? Kiedy się p...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>To po co występowaliśmy o derogację do UE  \\n@...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Przeca żeś bogaty, skoro Polski ład Ci zabiera!</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Polski Ład? A dziękuję, nie narzekam. No może ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3048</th>\n",
              "      <td>4009</td>\n",
              "      <td>No to jest Pan ciekawym przypadkiem „wierząceg...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>4010</td>\n",
              "      <td>Wyluzujcie z tymi korzyściami. Już Polski Ład ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>4011</td>\n",
              "      <td>A PiS jaki ma program? Pytam w zakresie podatk...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3051</th>\n",
              "      <td>4012</td>\n",
              "      <td>5\\n10\\n142</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3052</th>\n",
              "      <td>4013</td>\n",
              "      <td>Jakub Chełstowski\\n@JakubChe\\n · 2 mar\\nZarząd...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3053 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43b9878d-640a-465a-836b-def2ff24ed3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43b9878d-640a-465a-836b-def2ff24ed3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43b9878d-640a-465a-836b-def2ff24ed3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.drop('Subjectivity',axis=1,inplace=True)\n",
        "df2.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "SknHoZOsRcge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QhuSpp5TRhV2",
        "outputId": "4dccccee-ee72-4f4d-f18d-3e0f12ce8d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text\n",
              "0     #pis #PolskiŁad Trybunał Konstytucyjny od kuch...\n",
              "1     Wiecie kiedy pisowiec mówi prawdę? Kiedy się p...\n",
              "2     To po co występowaliśmy o derogację do UE  \\n@...\n",
              "3      Przeca żeś bogaty, skoro Polski ład Ci zabiera! \n",
              "4     Polski Ład? A dziękuję, nie narzekam. No może ...\n",
              "...                                                 ...\n",
              "3048  No to jest Pan ciekawym przypadkiem „wierząceg...\n",
              "3049  Wyluzujcie z tymi korzyściami. Już Polski Ład ...\n",
              "3050  A PiS jaki ma program? Pytam w zakresie podatk...\n",
              "3051                                         5\\n10\\n142\n",
              "3052  Jakub Chełstowski\\n@JakubChe\\n · 2 mar\\nZarząd...\n",
              "\n",
              "[3053 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d447e69-934b-4252-a9a0-d6021290b692\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#pis #PolskiŁad Trybunał Konstytucyjny od kuch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wiecie kiedy pisowiec mówi prawdę? Kiedy się p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To po co występowaliśmy o derogację do UE  \\n@...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Przeca żeś bogaty, skoro Polski ład Ci zabiera!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Polski Ład? A dziękuję, nie narzekam. No może ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3048</th>\n",
              "      <td>No to jest Pan ciekawym przypadkiem „wierząceg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>Wyluzujcie z tymi korzyściami. Już Polski Ład ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>A PiS jaki ma program? Pytam w zakresie podatk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3051</th>\n",
              "      <td>5\\n10\\n142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3052</th>\n",
              "      <td>Jakub Chełstowski\\n@JakubChe\\n · 2 mar\\nZarząd...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3053 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d447e69-934b-4252-a9a0-d6021290b692')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d447e69-934b-4252-a9a0-d6021290b692 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d447e69-934b-4252-a9a0-d6021290b692');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oV8iBCsyRjUW",
        "outputId": "ccb43e7a-82b7-42a0-c954-e14698aedbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text\n",
              "0     #pis #PolskiŁad Trybunał Konstytucyjny od kuch...\n",
              "1     Wiecie kiedy pisowiec mówi prawdę? Kiedy się p...\n",
              "2     To po co występowaliśmy o derogację do UE  \\n@...\n",
              "3      Przeca żeś bogaty, skoro Polski ład Ci zabiera! \n",
              "4     Polski Ład? A dziękuję, nie narzekam. No może ...\n",
              "...                                                 ...\n",
              "3048  No to jest Pan ciekawym przypadkiem „wierząceg...\n",
              "3049  Wyluzujcie z tymi korzyściami. Już Polski Ład ...\n",
              "3050  A PiS jaki ma program? Pytam w zakresie podatk...\n",
              "3051                                         5\\n10\\n142\n",
              "3052  Jakub Chełstowski\\n@JakubChe\\n · 2 mar\\nZarząd...\n",
              "\n",
              "[3053 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eba04be1-b599-4c5e-b7cd-03cd5f0257bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#pis #PolskiŁad Trybunał Konstytucyjny od kuch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wiecie kiedy pisowiec mówi prawdę? Kiedy się p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To po co występowaliśmy o derogację do UE  \\n@...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Przeca żeś bogaty, skoro Polski ład Ci zabiera!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Polski Ład? A dziękuję, nie narzekam. No może ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3048</th>\n",
              "      <td>No to jest Pan ciekawym przypadkiem „wierząceg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>Wyluzujcie z tymi korzyściami. Już Polski Ład ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>A PiS jaki ma program? Pytam w zakresie podatk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3051</th>\n",
              "      <td>5\\n10\\n142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3052</th>\n",
              "      <td>Jakub Chełstowski\\n@JakubChe\\n · 2 mar\\nZarząd...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3053 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eba04be1-b599-4c5e-b7cd-03cd5f0257bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eba04be1-b599-4c5e-b7cd-03cd5f0257bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eba04be1-b599-4c5e-b7cd-03cd5f0257bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(x):\n",
        "  encoded_raw = tokenizer.encode_plus(\n",
        "  x,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        "  )\n",
        "  input_ids = encoded_raw['input_ids'].to(device)\n",
        "  attention_mask = encoded_raw['attention_mask'].to(device)\n",
        "\n",
        "  output = model(input_ids, attention_mask)\n",
        "  _, prediction = torch.max(output, dim=1)\n",
        "  return class_names[prediction]"
      ],
      "metadata": {
        "id": "ENkjEKY8RmT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Pred']=df2[\"Text\"].apply(sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVy7oyRBR97W",
        "outputId": "abcff0cc-80a9-43ab-9e9a-18162b4c8cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def cleanText(text):\n",
        "    text=re.sub(r':','',text)\n",
        "    text=re.sub(r';','',text)\n",
        "    text=re.sub(r'[0-9]+','',text)\n",
        "    text=re.sub(r'  ',' ',text)\n",
        "    text=re.sub(r'#','',text)\n",
        "    text=re.sub(r'-','',text)\n",
        "    text=re.sub(r',','',text)\n",
        "    text=re.sub(r'\"','',text)\n",
        "    text=re.sub(r\"'\",'',text)\n",
        "    text=re.sub(r'/','',text)\n",
        "    return text\n",
        "df2['Text']=df2['Text'].apply(cleanText)"
      ],
      "metadata": {
        "id": "d77yfj-LR9Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.Pred.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5XJwCoYSHVz",
        "outputId": "df319d9e-bed3-406c-e283-efa935b9758c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    2661\n",
              "positive     392\n",
              "Name: Pred, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette('pastel')[0:5]\n",
        "plus=(df2.Pred.values=='positive').sum()\n",
        "minus=(df2.Pred.values=='negative').sum()\n",
        "data=[minus, plus]\n",
        "labels=['negative','positive']\n",
        "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Ymlv1ECMSZHJ",
        "outputId": "dff4db23-840c-4be7-e39c-9fb45910dbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 273,
              "height": 231
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ljz2VtD-aPel"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}